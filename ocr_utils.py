import time
import io
import base64
import unicodedata
from PIL import Image
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
import easyocr
import torch
import numpy as np
from selenium.webdriver.common.by import By
from appium.webdriver.webdriver import WebDriver
from selenium.webdriver.common.actions.action_builder import ActionBuilder
from selenium.webdriver.common.actions.pointer_input import PointerInput

reader = easyocr.Reader(['vi'], gpu=True)

def take_screenshot_and_ocr(driver: WebDriver):
    print("üñºÔ∏è B·∫Øt ƒë·∫ßu screenshot v√† OCR...")
    print(torch.backends.mps.is_available())
    start_time = time.time()

    # L·∫•y ·∫£nh screenshot
    screenshot_base64 = driver.get_screenshot_as_base64()
    image_bytes = base64.b64decode(screenshot_base64)
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

    # Resize ·∫£nh n·∫øu qu√° l·ªõn
    max_width = 640
    w, h = image.size
    if w > max_width:
        ratio = max_width / w
        image = image.resize((int(w * ratio), int(h * ratio)))

    # Ch·∫°y OCR
    results = reader.readtext(np.array(image), detail=1)

    # ƒêo th·ªùi gian ho√†n t·∫•t
    duration = time.time() - start_time
    print(f"‚úÖ OCR ho√†n t·∫•t. T√¨m th·∫•y {len(results)} d√≤ng vƒÉn b·∫£n. ‚è±Ô∏è M·∫•t {duration:.2f} gi√¢y.")

    return results, image

def tap_at(driver, x, y):
    finger = PointerInput("touch", "finger")
    actions = ActionBuilder(driver, mouse=finger)  # Truy·ªÅn finger v√†o tham s·ªë mouse
    
    actions.pointer_action.move_to_location(x, y)
    actions.pointer_action.pointer_down()
    actions.pointer_action.pause(0.1)
    actions.pointer_action.pointer_up()

    actions.perform()

def normalize_text(text):
    """
    Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng v√† lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát.
    """
    text = text.lower()
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    return text

# def find_text_and_tap(driver: WebDriver, keyword: str, exact_match: bool = True) -> bool:
    
    results, img = take_screenshot_and_ocr(driver)
    print("OCR image size:", img.size)
    window_size = driver.get_window_size()
    print("Device screen size:", window_size)
    scale_x = window_size['width'] / img.size[0]
    scale_y = window_size['height'] / img.size[1]

    keyword_norm = normalize_text(keyword)

    print("[OCR] C√°c text t√¨m ƒë∆∞·ª£c tr√™n m√†n h√¨nh:")
    for detection in results:
        text_raw = detection[1].strip()
        print(f"  - {text_raw}")

    for detection in results:
        text_raw = detection[1].strip()
        text_norm = normalize_text(text_raw)

        if (exact_match and keyword_norm == text_norm) or (not exact_match and keyword_norm in text_norm):
            coords = detection[0]
            x = int((coords[0][0] + coords[2][0]) / 2)
            y = int((coords[0][1] + coords[2][1]) / 2)
            print(f"[OCR] Found {'exact match' if exact_match else 'partial match'} '{text_raw}' ‚Üí Tap at ({x},{y})")
            x_real = int(x * scale_x)
            y_real = int(y * scale_y)
            tap_at(driver, x_real, y_real)
            return True
    print(f"[OCR] '{keyword}' not found on screen (normalized)")
    return False

def find_text_and_tap(driver: WebDriver, keywords: str, exact_match: bool = True) -> bool:
    results, img = take_screenshot_and_ocr(driver)
    print(f"OCR image find:{keywords}")
    window_size = driver.get_window_size()
    print("Device screen size:", window_size)
    scale_x = window_size['width'] / img.size[0]
    scale_y = window_size['height'] / img.size[1]

    # Chuy·ªÉn th√†nh list v√† normalize t·ª´ng t·ª´ kh√≥a
    keyword_list = [normalize_text(k.strip()) for k in keywords.split(';') if k.strip()]
    print(f"[OCR] T√¨m c√°c t·ª´ kh√≥a: {keyword_list}")

    print("[OCR] C√°c text t√¨m ƒë∆∞·ª£c tr√™n m√†n h√¨nh:")
    for detection in results:
        text_raw = detection[1].strip()
        print(f"  - {text_raw}")

    for detection in results:
        text_raw = detection[1].strip()
        text_norm = normalize_text(text_raw)

        for keyword_norm in keyword_list:
            if (exact_match and keyword_norm == text_norm) or (not exact_match and keyword_norm in text_norm):
                coords = detection[0]
                x = int((coords[0][0] + coords[2][0]) / 2)
                y = int((coords[0][1] + coords[2][1]) / 2)
                print(f"[OCR] Found {'exact match' if exact_match else 'partial match'} '{text_raw}' ‚Üí Tap at ({x},{y})")
                x_real = int(x * scale_x)
                y_real = int(y * scale_y)
                tap_at(driver, x_real, y_real)
                return True

    print(f"[OCR] Kh√¥ng t√¨m th·∫•y t·ª´ kh√≥a n√†o trong: {keywords}")
    return False


def wait_and_find_text_and_tap(driver: WebDriver, keyword: str, exact_match: bool = True) -> bool:
    for _ in range(3):
        results, img = take_screenshot_and_ocr(driver)
        print(f"OCR image find:{keyword}")
        window_size = driver.get_window_size()
        print("Device screen size:", window_size)
        scale_x = window_size['width'] / img.size[0]
        scale_y = window_size['height'] / img.size[1]

        keyword_norm = normalize_text(keyword)

        print("[OCR] C√°c text t√¨m ƒë∆∞·ª£c tr√™n m√†n h√¨nh:")
        for detection in results:
            text_raw = detection[1].strip()
            print(f"  - {text_raw}")

        for detection in results:
            text_raw = detection[1].strip()
            text_norm = normalize_text(text_raw)

            if (exact_match and keyword_norm == text_norm) or (not exact_match and keyword_norm in text_norm):
                coords = detection[0]
                x = int((coords[0][0] + coords[2][0]) / 2)
                y = int((coords[0][1] + coords[2][1]) / 2)
                print(f"[OCR] Found {'exact match' if exact_match else 'partial match'} '{text_raw}' ‚Üí Tap at ({x},{y})")
                x_real = int(x * scale_x)
                y_real = int(y * scale_y)
                tap_at(driver, x_real, y_real)
                time.sleep(3)
                return True
        time.sleep(1)
    print(f"[OCR] '{keyword}' not found on screen (normalized)")
    return False


def find_text_and_tap_with_index(driver: WebDriver, keyword: str, index: int = 0, exact_match: bool = True) -> bool:
    results, img = take_screenshot_and_ocr(driver)

    print("OCR image size:", img.size)
    window_size = driver.get_window_size()
    print("Device screen size:", window_size)
    scale_x = window_size['width'] / img.size[0]
    scale_y = window_size['height'] / img.size[1]

    keyword_norm = normalize_text(keyword)
    matched_elements = []

    print("[OCR] C√°c text t√¨m ƒë∆∞·ª£c tr√™n m√†n h√¨nh:")
    for detection in results:
        text_raw = detection[1].strip()
        print(f"  - {text_raw}")

    # T√¨m t·∫•t c·∫£ text kh·ªõp
    for detection in results:
        text_raw = detection[1].strip()
        text_norm = normalize_text(text_raw)

        if (exact_match and keyword_norm == text_norm) or (not exact_match and keyword_norm in text_norm):
            matched_elements.append((detection, text_raw))

    # N·∫øu kh√¥ng c√≥ k·∫øt qu·∫£ kh·ªõp
    if not matched_elements:
        print(f"[OCR] '{keyword}' not found on screen (normalized)")
        return False

    if index >= len(matched_elements):
        print(f"[OCR] C√≥ {len(matched_elements)} k·∫øt qu·∫£ kh·ªõp, nh∆∞ng index {index} v∆∞·ª£t qu√° ph·∫°m vi.")
        return False

    # L·∫•y ph·∫ßn t·ª≠ theo index
    detection, text_raw = matched_elements[index]
    coords = detection[0]
    x = int((coords[0][0] + coords[2][0]) / 2)
    y = int((coords[0][1] + coords[2][1]) / 2)
    x_real = int(x * scale_x)
    y_real = int(y * scale_y)

    print(f"[OCR] Tapping v√†o k·∫øt qu·∫£ #{index}: '{text_raw}' ‚Üí Tap at ({x_real},{y_real})")
    tap_at(driver, x_real, y_real)
    time.sleep(3)
    return True


def input_text(driver: WebDriver, text: str, is_password: bool = False, index: int = 0, is_finder: bool = False):
    print(f"[Input] Typing: {text}")
    try:
        # Ch·ªçn lo·∫°i input field theo ki·ªÉu (text th∆∞·ªùng hay password)
        if is_password:
            input_fields = driver.find_elements(By.CLASS_NAME, "XCUIElementTypeSecureTextField")
        elif is_finder:
            input_fields = driver.find_elements(By.CLASS_NAME, "XCUIElementTypeSearchField")
        else:
            input_fields = driver.find_elements(By.CLASS_NAME, "XCUIElementTypeTextField")

        if not input_fields:
            print("[Input] Kh√¥ng t√¨m th·∫•y √¥ nh·∫≠p li·ªáu")
            return

        if index >= len(input_fields):
            print(f"[Input] Index {index} v∆∞·ª£t qu√° s·ªë l∆∞·ª£ng √¥ nh·∫≠p ({len(input_fields)})")
            return

        input_field = input_fields[index]
        input_field.click()
        input_field.clear()
        input_field.send_keys(text)
        time.sleep(1)

    except Exception as e:
        print(f"[Input] L·ªói khi nh·∫≠p text: {e}")
